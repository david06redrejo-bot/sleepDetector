---
title: Drowsiness Detector
emoji: ğŸ˜´
colorFrom: blue
colorTo: red
sdk: streamlit
sdk_version: 1.41.1
python_version: "3.10"
app_file: main.py
pinned: false
---

# ğŸ§  NeuroVigilance â€” Drowsiness Detection System

A real-time drowsiness detection system using Computer Vision and AI.  
**Premium safety monitoring dashboard with WebRTC streaming.**

[![Live Demo](https://img.shields.io/badge/ğŸš€_Live_Demo-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/david06redrejo-bot/drowsiness-detector)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/SDK-Streamlit-FF4B4B)
![OpenCV](https://img.shields.io/badge/Computer_Vision-OpenCV-green)
![MediaPipe](https://img.shields.io/badge/AI-MediaPipe-orange)

---

## ğŸ¯ Overview

This project uses **MediaPipe Face Mesh** to detect facial landmarks and calculate the **Eye Aspect Ratio (EAR)**. If the user's eyes stay closed for a consecutive number of frames, the system triggers an audio alarm.

### âœ¨ Key Features

- **Real-Time Monitoring** â€” Low-latency video processing
- **Premium UI** â€” Glassmorphism design with micro-animations
- **Web & Desktop** â€” Run locally or deploy to the cloud
- **Robust Connectivity** â€” STUN + TURN servers for reliable WebRTC
- **Privacy First** â€” Video is processed in memory, never saved

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Webcam
- pip (Python package manager)

### Installation

```bash
# Clone the repository
git clone https://github.com/david06redrejo-bot/sleepDetector.git
cd sleepDetector

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ’» Running the Application

### Option 1: ğŸŒ **Live Demo (No Installation)**

Try it instantly on Hugging Face:

ğŸ‘‰ **[https://huggingface.co/spaces/david06redrejo-bot/drowsiness-detector](https://huggingface.co/spaces/david06redrejo-bot/drowsiness-detector)**

---

### Option 2: ğŸ–¥ï¸ **Local Debug Mode (Desktop App)**

Best for development and testing with minimal latency.

```bash
python local_debug.py
```

**Features:**
- Uses OpenCV window (no browser needed)
- Direct webcam access
- Server-side audio playback (pygame)
- Fastest response time

**Controls:**
- Press `Q` to quit

---

### Option 3: ğŸŒ **Streamlit Web App (Local Server)**

Run the full web interface locally.

```bash
streamlit run main.py
```

**Features:**
- Full premium UI with glassmorphism design
- WebRTC video streaming
- Browser-based audio alerts
- Same experience as Hugging Face, but on your machine

**After running:**
1. Browser opens automatically at `http://localhost:8501`
2. Click **START** to enable camera
3. Grant camera permissions when prompted
4. Close your eyes for ~3 seconds to trigger the alarm

---

## âš™ï¸ Configuration

Detection parameters can be adjusted in `src/config.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `EYE_ASPECT_RATIO_THRESHOLD` | 0.20 | EAR below this = eyes closed |
| `EYE_ASPECT_RATIO_CONSEC_FRAMES` | 12 | Frames before alarm triggers |

---

## ğŸ“ Project Structure

```text
sleepDetector/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ alarm.wav          # Alarm sound file
â”‚   â””â”€â”€ style.css          # Premium UI styles
â”œâ”€â”€ models/
â”‚   â””â”€â”€ face_landmarker.task   # MediaPipe model
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py          # Detection parameters
â”‚   â”œâ”€â”€ rtc_config.py      # WebRTC STUN/TURN settings
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ geometry.py    # EAR calculation
â”‚       â””â”€â”€ sound.py       # Audio handling
â”œâ”€â”€ guide/
â”‚   â”œâ”€â”€ WEBRTC_CONFIGURATION.md
â”‚   â””â”€â”€ HUGGING_FACE_DEPLOYMENT.md
â”œâ”€â”€ main.py                # Streamlit web app
â”œâ”€â”€ local_debug.py         # Desktop OpenCV app
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ packages.txt           # System dependencies (Linux)
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Face Detection** | MediaPipe Face Landmarker |
| **Computer Vision** | OpenCV |
| **Web Framework** | Streamlit |
| **Video Streaming** | WebRTC (streamlit-webrtc) |
| **Audio** | Pygame (local) / HTML5 Audio (web) |
| **Deployment** | Hugging Face Spaces |

---

## ğŸ“Š How It Works

```
1. Webcam captures video frames
           â†“
2. MediaPipe detects face landmarks
           â†“
3. Calculate Eye Aspect Ratio (EAR)
           â†“
4. EAR < threshold for N consecutive frames?
           â†“
   YES â†’ ğŸ”Š TRIGGER ALARM
   NO  â†’ Continue monitoring
```

---

## ğŸ“ License

MIT License â€” Feel free to use and modify!

---

## ğŸ™ Acknowledgments

- [MediaPipe](https://mediapipe.dev/) â€” Face landmark detection
- [Streamlit](https://streamlit.io/) â€” Web framework
- [Metered.ca](https://www.metered.ca/) â€” Free TURN servers

---

<p align="center">
  <b>Built for safety â€¢ Real-time AI monitoring</b><br>
  ğŸ§  NeuroVigilance
</p>
